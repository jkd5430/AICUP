{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAsgOM1pluN1FTXPBleiPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkd5430/AICUP/blob/main/pytroch_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "O_A9xP0Ue9sB"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class conv(nn.Module):\n",
        "  def __init__(self, inn, out):\n",
        "    super().__init__()\n",
        "    self.inn = inn\n",
        "    self.out = out\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(self.inn,self.out,3,padding=1),\n",
        "        nn.BatchNorm2d(self.out),\n",
        "        nn.ReLU()\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "rMFihYc8hn_V"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pool(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.pool = nn.Sequential(\n",
        "        nn.MaxPool2d(2)\n",
        "\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.pool(x)"
      ],
      "metadata": {
        "id": "b4tl7wm1la2J"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2DTranspose(nn.Module):\n",
        "  def __init__(self, inn, out):\n",
        "    self.inn = inn\n",
        "    self.out = out\n",
        "    super().__init__()\n",
        "    self.tconv = nn.Sequential(\n",
        "        nn.ConvTranspose2d(self.inn,self.out,2,2)\n",
        "\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.tconv(x)"
      ],
      "metadata": {
        "id": "c_D9AF2q2qN_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class unet(nn.Module):\n",
        "  def __init__(self,in_channel=3,out_channel=3):\n",
        "    super().__init__()\n",
        "    self.in_channel = in_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.conv1 = conv(in_channel, 64)\n",
        "    self.conv2 = conv(64, 64)\n",
        "    self.pool1 = pool()\n",
        "    self.conv3 = conv(64, 128)\n",
        "    self.conv4 = conv(128, 128)\n",
        "    self.pool2 = pool()\n",
        "    self.conv5 = conv(128, 256)\n",
        "    self.conv6 = conv(256, 256)\n",
        "    self.pool3 = pool()\n",
        "    self.conv7 = conv(256, 512)\n",
        "    self.conv8 = conv(512, 512)\n",
        "    self.pool4 = pool()\n",
        "    self.conv9 = conv(512, 1024)\n",
        "    self.conv10 = conv(1024, 1024)\n",
        "    self.tconv1 = Conv2DTranspose(1024, 512)\n",
        "    self.conv11 = conv(1024, 512)\n",
        "    self.conv12 = conv(512, 512)\n",
        "    self.tconv2 = Conv2DTranspose(512, 256)\n",
        "    self.conv13 = conv(512, 256)\n",
        "    self.conv14 = conv(256, 256)\n",
        "    self.tconv3 = Conv2DTranspose(256, 128)\n",
        "    self.conv15 = conv(256, 128)\n",
        "    self.conv16 = conv(128, 128)\n",
        "    self.tconv4 = Conv2DTranspose(128, 64)\n",
        "    self.conv17 = conv(128, 64)\n",
        "    self.conv18 = conv(64, 64)\n",
        "    self.conv19 = conv(64,64)\n",
        "    self.conv20 = conv(64,out_channel)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.conv2(x1)\n",
        "    x3 = self.pool1(x2)\n",
        "    x4 = self.conv3(x3)\n",
        "    x5 = self.conv4(x4)\n",
        "    x6 = self.pool2(x5)\n",
        "    x7 = self.conv5(x6)\n",
        "    x8 = self.conv6(x7)\n",
        "    x9 = self.pool3(x8)\n",
        "    x10 = self.conv7(x9)\n",
        "    x11 = self.conv8(x10)\n",
        "    x12 = self.pool4(x11)\n",
        "    x13 = self.conv9(x12)\n",
        "    x14 = self.conv10(x13)\n",
        "    x15 = self.tconv1(x14)\n",
        "    x16 =torch.cat((x15,x11),1)\n",
        "    x17 = self.conv11(x16)\n",
        "    x18 = self.conv12(x17)\n",
        "    x19 = self.tconv2(x18)\n",
        "    x20 = torch.cat((x19,x8),1)\n",
        "    x21 = self.conv13(x20)\n",
        "    x22 = self.conv14(x21)\n",
        "    x23 = self.tconv3(x22)\n",
        "    x24 = torch.cat((x23,x5),1)\n",
        "    x25 = self.conv15(x24)\n",
        "    x26 = self.conv16(x25)\n",
        "    x27 = self.tconv4(x26)\n",
        "    x28 = torch.cat((x27,x2),1)\n",
        "    x29 = self.conv17(x28)\n",
        "    x30 = self.conv18(x29)\n",
        "    x31 = self.conv19(x30)\n",
        "    x32 = self.conv20(x31)\n",
        "    return x32\n",
        "x=unet(3,3)\n",
        "summary(x,(3,512,512))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnM7rQ62nIag",
        "outputId": "27f0ad32-9055-4d85-d9ca-c6b862c39c06"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
            "              ReLU-3         [-1, 64, 512, 512]               0\n",
            "              conv-4         [-1, 64, 512, 512]               0\n",
            "            Conv2d-5         [-1, 64, 512, 512]          36,928\n",
            "       BatchNorm2d-6         [-1, 64, 512, 512]             128\n",
            "              ReLU-7         [-1, 64, 512, 512]               0\n",
            "              conv-8         [-1, 64, 512, 512]               0\n",
            "         MaxPool2d-9         [-1, 64, 256, 256]               0\n",
            "             pool-10         [-1, 64, 256, 256]               0\n",
            "           Conv2d-11        [-1, 128, 256, 256]          73,856\n",
            "      BatchNorm2d-12        [-1, 128, 256, 256]             256\n",
            "             ReLU-13        [-1, 128, 256, 256]               0\n",
            "             conv-14        [-1, 128, 256, 256]               0\n",
            "           Conv2d-15        [-1, 128, 256, 256]         147,584\n",
            "      BatchNorm2d-16        [-1, 128, 256, 256]             256\n",
            "             ReLU-17        [-1, 128, 256, 256]               0\n",
            "             conv-18        [-1, 128, 256, 256]               0\n",
            "        MaxPool2d-19        [-1, 128, 128, 128]               0\n",
            "             pool-20        [-1, 128, 128, 128]               0\n",
            "           Conv2d-21        [-1, 256, 128, 128]         295,168\n",
            "      BatchNorm2d-22        [-1, 256, 128, 128]             512\n",
            "             ReLU-23        [-1, 256, 128, 128]               0\n",
            "             conv-24        [-1, 256, 128, 128]               0\n",
            "           Conv2d-25        [-1, 256, 128, 128]         590,080\n",
            "      BatchNorm2d-26        [-1, 256, 128, 128]             512\n",
            "             ReLU-27        [-1, 256, 128, 128]               0\n",
            "             conv-28        [-1, 256, 128, 128]               0\n",
            "        MaxPool2d-29          [-1, 256, 64, 64]               0\n",
            "             pool-30          [-1, 256, 64, 64]               0\n",
            "           Conv2d-31          [-1, 512, 64, 64]       1,180,160\n",
            "      BatchNorm2d-32          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-33          [-1, 512, 64, 64]               0\n",
            "             conv-34          [-1, 512, 64, 64]               0\n",
            "           Conv2d-35          [-1, 512, 64, 64]       2,359,808\n",
            "      BatchNorm2d-36          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-37          [-1, 512, 64, 64]               0\n",
            "             conv-38          [-1, 512, 64, 64]               0\n",
            "        MaxPool2d-39          [-1, 512, 32, 32]               0\n",
            "             pool-40          [-1, 512, 32, 32]               0\n",
            "           Conv2d-41         [-1, 1024, 32, 32]       4,719,616\n",
            "      BatchNorm2d-42         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-43         [-1, 1024, 32, 32]               0\n",
            "             conv-44         [-1, 1024, 32, 32]               0\n",
            "           Conv2d-45         [-1, 1024, 32, 32]       9,438,208\n",
            "      BatchNorm2d-46         [-1, 1024, 32, 32]           2,048\n",
            "             ReLU-47         [-1, 1024, 32, 32]               0\n",
            "             conv-48         [-1, 1024, 32, 32]               0\n",
            "  ConvTranspose2d-49          [-1, 512, 64, 64]       2,097,664\n",
            "  Conv2DTranspose-50          [-1, 512, 64, 64]               0\n",
            "           Conv2d-51          [-1, 512, 64, 64]       4,719,104\n",
            "      BatchNorm2d-52          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-53          [-1, 512, 64, 64]               0\n",
            "             conv-54          [-1, 512, 64, 64]               0\n",
            "           Conv2d-55          [-1, 512, 64, 64]       2,359,808\n",
            "      BatchNorm2d-56          [-1, 512, 64, 64]           1,024\n",
            "             ReLU-57          [-1, 512, 64, 64]               0\n",
            "             conv-58          [-1, 512, 64, 64]               0\n",
            "  ConvTranspose2d-59        [-1, 256, 128, 128]         524,544\n",
            "  Conv2DTranspose-60        [-1, 256, 128, 128]               0\n",
            "           Conv2d-61        [-1, 256, 128, 128]       1,179,904\n",
            "      BatchNorm2d-62        [-1, 256, 128, 128]             512\n",
            "             ReLU-63        [-1, 256, 128, 128]               0\n",
            "             conv-64        [-1, 256, 128, 128]               0\n",
            "           Conv2d-65        [-1, 256, 128, 128]         590,080\n",
            "      BatchNorm2d-66        [-1, 256, 128, 128]             512\n",
            "             ReLU-67        [-1, 256, 128, 128]               0\n",
            "             conv-68        [-1, 256, 128, 128]               0\n",
            "  ConvTranspose2d-69        [-1, 128, 256, 256]         131,200\n",
            "  Conv2DTranspose-70        [-1, 128, 256, 256]               0\n",
            "           Conv2d-71        [-1, 128, 256, 256]         295,040\n",
            "      BatchNorm2d-72        [-1, 128, 256, 256]             256\n",
            "             ReLU-73        [-1, 128, 256, 256]               0\n",
            "             conv-74        [-1, 128, 256, 256]               0\n",
            "           Conv2d-75        [-1, 128, 256, 256]         147,584\n",
            "      BatchNorm2d-76        [-1, 128, 256, 256]             256\n",
            "             ReLU-77        [-1, 128, 256, 256]               0\n",
            "             conv-78        [-1, 128, 256, 256]               0\n",
            "  ConvTranspose2d-79         [-1, 64, 512, 512]          32,832\n",
            "  Conv2DTranspose-80         [-1, 64, 512, 512]               0\n",
            "           Conv2d-81         [-1, 64, 512, 512]          73,792\n",
            "      BatchNorm2d-82         [-1, 64, 512, 512]             128\n",
            "             ReLU-83         [-1, 64, 512, 512]               0\n",
            "             conv-84         [-1, 64, 512, 512]               0\n",
            "           Conv2d-85         [-1, 64, 512, 512]          36,928\n",
            "      BatchNorm2d-86         [-1, 64, 512, 512]             128\n",
            "             ReLU-87         [-1, 64, 512, 512]               0\n",
            "             conv-88         [-1, 64, 512, 512]               0\n",
            "           Conv2d-89         [-1, 64, 512, 512]          36,928\n",
            "      BatchNorm2d-90         [-1, 64, 512, 512]             128\n",
            "             ReLU-91         [-1, 64, 512, 512]               0\n",
            "             conv-92         [-1, 64, 512, 512]               0\n",
            "           Conv2d-93          [-1, 3, 512, 512]           1,731\n",
            "      BatchNorm2d-94          [-1, 3, 512, 512]               6\n",
            "             ReLU-95          [-1, 3, 512, 512]               0\n",
            "             conv-96          [-1, 3, 512, 512]               0\n",
            "================================================================\n",
            "Total params: 31,082,249\n",
            "Trainable params: 31,082,249\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.00\n",
            "Forward/backward pass size (MB): 5040.00\n",
            "Params size (MB): 118.57\n",
            "Estimated Total Size (MB): 5161.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = torch.rand(3,512,512)\n",
        "b = np.expand_dims(a,0)\n",
        "\n",
        "c = torch.from_numpy(b)\n",
        "x(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiCLdvQ-Knpn",
        "outputId": "a3fb708a-9411-42cb-e685-130b525f9891"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000, 0.2701, 0.2798,  ..., 0.0000, 0.5719, 0.4122],\n",
              "          [1.4735, 0.0237, 0.3052,  ..., 1.2696, 0.0000, 0.9588],\n",
              "          [0.8274, 0.5875, 0.0000,  ..., 0.0000, 0.0000, 0.3490],\n",
              "          ...,\n",
              "          [0.5705, 1.3811, 2.0652,  ..., 0.0000, 0.3647, 0.9256],\n",
              "          [0.1232, 0.0000, 1.2542,  ..., 0.0000, 0.0000, 0.8008],\n",
              "          [0.0000, 0.0000, 0.1902,  ..., 0.7520, 0.7489, 1.6908]],\n",
              "\n",
              "         [[0.0855, 0.9921, 0.0000,  ..., 0.3550, 0.4221, 0.0000],\n",
              "          [0.2482, 1.9377, 2.4632,  ..., 0.3549, 1.3369, 1.3741],\n",
              "          [0.5808, 0.7781, 0.4818,  ..., 0.0000, 1.1199, 1.1980],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.1754,  ..., 0.3443, 0.8710, 0.0000],\n",
              "          [0.0000, 0.2604, 0.0000,  ..., 0.1821, 0.2873, 0.0000],\n",
              "          [1.0930, 0.6154, 1.0275,  ..., 0.8542, 0.1583, 0.3841]],\n",
              "\n",
              "         [[0.4468, 0.4950, 0.8505,  ..., 0.0000, 0.6034, 1.4247],\n",
              "          [0.0000, 0.0219, 0.0000,  ..., 0.0000, 0.0000, 0.8634],\n",
              "          [0.0000, 0.0000, 1.3076,  ..., 0.6305, 0.2368, 0.0470],\n",
              "          ...,\n",
              "          [0.0000, 0.5877, 0.3751,  ..., 0.3104, 0.0000, 0.6777],\n",
              "          [0.0000, 0.0000, 0.4712,  ..., 0.0000, 0.0000, 1.4219],\n",
              "          [0.0000, 0.0000, 0.1799,  ..., 0.9177, 0.0000, 0.7444]]]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}